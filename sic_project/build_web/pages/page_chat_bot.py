import streamlit as st
from datetime import datetime
from pages.chat_bot import build_qa_chain, ask_chatbot, get_query_results_debug
import time
from utils.load_data import load_news_data

def show_chat():
    """Hi·ªÉn th·ªã giao di·ªán chat v·ªõi RAG + GPT API"""
    
    # ·∫®n navigation menu v√† custom CSS
    hide_navbar = """
    <style>
    [data-testid="stSidebarNav"] {
        display: none;
    }
    .stApp > header {
        background-color: transparent;
    }
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .chat-message {
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 10px;
        border-left: 4px solid #2196f3;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left-color: #2196f3;
    }
    .bot-message {
        background-color: #f1f8e9;
        border-left-color: #4caf50;
    }
    .source-info {
        background-color: #fff3e0;
        padding: 0.8rem;
        border-radius: 8px;
        border-left: 3px solid #ff9800;
        margin-top: 1rem;
        font-size: 0.9rem;
    }
    .query-results {
        background-color: #fce4ec;
        padding: 1rem;
        border-radius: 8px;
        border-left: 3px solid #e91e63;
        margin: 1rem 0;
        max-height: 200px;
        overflow-y: auto;
    }
    .processing-step {
        background-color: #f5f5f5;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        margin: 0.3rem 0;
        border-left: 3px solid #9e9e9e;
    }
    .error-message {
        background-color: #ffebee;
        color: #c62828;
        padding: 1rem;
        border-radius: 8px;
        border-left: 3px solid #f44336;
        margin: 1rem 0;
    }
    .success-message {
        background-color: #e8f5e8;
        color: #2e7d32;
        padding: 1rem;
        border-radius: 8px;
        border-left: 3px solid #4caf50;
        margin: 1rem 0;
    }
    .stats-container {
        display: flex;
        justify-content: space-around;
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .stat-item {
        text-align: center;
        padding: 0.5rem;
    }
    .stat-number {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2196f3;
    }
    .stat-label {
        font-size: 0.9rem;
        color: #666;
    }
    .rag-status {
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.5rem 0;
        text-align: center;
        font-weight: bold;
    }
    .rag-found {
        background-color: #e8f5e8;
        color: #2e7d32;
        border: 1px solid #4caf50;
    }
    .rag-not-found {
        background-color: #fff3e0;
        color: #e65100;
        border: 1px solid #ff9800;
    }
    </style>
    """
    st.markdown(hide_navbar, unsafe_allow_html=True)

    # Header v·ªõi thi·∫øt k·∫ø ƒë·∫πp
    st.markdown("""
    <div class="main-header">
        <h1 style='color: white; text-align: center; margin: 0;'>
            ü§ñ Chatbot H·ªèi ƒê√°p B√°o Ch√≠ Th√¥ng Minh
        </h1>
        <p style='color: white; text-align: center; margin: 0; opacity: 0.9;'>
            RAG + OpenAI GPT | Vector Search ‚Üí AI Processing ‚Üí Smart Answer
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar v·ªõi th√¥ng tin v√† th·ªëng k√™
    with st.sidebar:
        st.image("https://via.placeholder.com/150x100/667eea/white?text=AI+Bot", width=150)
        st.markdown("### üì∞ H·ªá Th·ªëng RAG + OpenAI")
        st.markdown("---")
        
        # Th·ªëng k√™ phi√™n chat
        total_questions = len(st.session_state.get('chat_history', []))
        rag_questions = sum(1 for chat in st.session_state.get('chat_history', []) if chat.get('has_rag_context', False))
        
        st.markdown(f"""
        <div class="stats-container">
            <div class="stat-item">
                <div class="stat-number">{total_questions}</div>
                <div class="stat-label">T·ªïng c√¢u h·ªèi</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">{rag_questions}</div>
                <div class="stat-label">D√πng RAG</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">{datetime.now().strftime('%H:%M')}</div>
                <div class="stat-label">Th·ªùi gian</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("### üîÑ Quy tr√¨nh x·ª≠ l√Ω")
        st.markdown("""
        1. **üîç Truy v·∫•n RAG**: T√¨m ki·∫øm vector database
        2. **üìä X·ª≠ l√Ω d·ªØ li·ªáu**: T·∫°o context t·ª´ k·∫øt qu·∫£ RAG
        3. **üß† OpenAI GPT**: Ph√¢n t√≠ch v√† t·∫°o c√¢u tr·∫£ l·ªùi
        4. **‚ú® K·∫øt qu·∫£**: Tr·∫£ l·ªùi th√¥ng minh v·ªõi ngu·ªìn
        """)
        
        st.markdown("---")
        st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t")
        
        # T√πy ch·ªçn hi·ªÉn th·ªã chi ti·∫øt
        show_rag_details = st.checkbox("Hi·ªÉn th·ªã chi ti·∫øt RAG", value=False)
        show_processing_steps = st.checkbox("Hi·ªÉn th·ªã c√°c b∆∞·ªõc x·ª≠ l√Ω", value=True)
        show_source_details = st.checkbox("Hi·ªÉn th·ªã th√¥ng tin ngu·ªìn", value=True)
        
        # T√πy ch·ªçn s·ªë l∆∞·ª£ng k·∫øt qu·∫£ truy v·∫•n
        max_results = st.slider("S·ªë k·∫øt qu·∫£ RAG t·ªëi ƒëa", 1, 10, 6)

    # Kh·ªüi t·∫°o session state
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'qa_chain' not in st.session_state:
        st.session_state.qa_chain = None
    if 'system_ready' not in st.session_state:
        st.session_state.system_ready = False

    # Kh·ªüi t·∫°o QA Chain (chatbot)
    if not st.session_state.system_ready:
        with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng RAG + OpenAI..."):
            try:
                st.session_state.qa_chain = build_qa_chain()
                st.session_state.system_ready = True
                st.success("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
            except Exception as e:
                st.error(f"‚ùå L·ªói kh·ªüi t·∫°o h·ªá th·ªëng: {str(e)}")
                st.stop()

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    if st.session_state.chat_history:
        st.markdown("### üí¨ L·ªãch s·ª≠ h·ªôi tho·∫°i")
        
        # Hi·ªÉn th·ªã c√°c tin nh·∫Øn theo th·ª© t·ª±
        for i, chat_item in enumerate(st.session_state.chat_history):
            question = chat_item['question']
            answer = chat_item['answer']
            sources = chat_item.get('sources', [])
            source_count = chat_item.get('source_count', 0)
            has_rag_context = chat_item.get('has_rag_context', False)
            processing_time = chat_item.get('processing_time', 0)
            detailed_sources = chat_item.get('detailed_sources', [])
            
            # Tin nh·∫Øn ng∆∞·ªùi d√πng
            st.markdown(f"""
            <div class="chat-message user-message">
                <strong>üßë B·∫°n:</strong> {question}
            </div>
            """, unsafe_allow_html=True)
            
            # Hi·ªÉn th·ªã tr·∫°ng th√°i RAG
            if has_rag_context:
                st.markdown(f"""
                <div class="rag-status rag-found">
                    ‚úÖ T√¨m th·∫•y {source_count} ngu·ªìn t·ª´ RAG
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="rag-status rag-not-found">
                    ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu RAG - S·ª≠ d·ª•ng ki·∫øn th·ª©c chung
                </div>
                """, unsafe_allow_html=True)
            
            # Tin nh·∫Øn bot
            st.markdown(f"""
            <div class="chat-message bot-message">
                <strong>ü§ñ Bot:</strong> {answer}
            </div>
            """, unsafe_allow_html=True)
            
            # Hi·ªÉn th·ªã th√¥ng tin ngu·ªìn n·∫øu c√≥
            if show_source_details and sources:
                st.markdown(f"""
                <div class="source-info">
                    <strong>üìö Ngu·ªìn tham kh·∫£o:</strong><br>
                    {chat_item.get('source_summary', 'Kh√¥ng c√≥ th√¥ng tin ngu·ªìn')}
                </div>
                """, unsafe_allow_html=True)
            
            # Th√¥ng tin chi ti·∫øt (c√≥ th·ªÉ ·∫©n/hi·ªán)
            with st.expander(f"üìã Chi ti·∫øt x·ª≠ l√Ω c√¢u h·ªèi {i+1}"):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"**‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω:** {processing_time:.2f}s")
                    st.markdown(f"**üîç Tr·∫°ng th√°i RAG:** {'‚úÖ C√≥ d·ªØ li·ªáu' if has_rag_context else '‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu'}")
                
                with col2:
                    st.markdown(f"**üìä S·ªë ngu·ªìn:** {source_count}")
                    st.markdown(f"**üïí Th·ªùi gian:** {chat_item.get('timestamp', 'N/A')}")
                
                with col3:
                    st.markdown(f"**üß† Model:** OpenAI GPT")
                    st.markdown(f"**üìù C√≥ context:** {'C√≥' if has_rag_context else 'Kh√¥ng'}")
                
                # Hi·ªÉn th·ªã chi ti·∫øt ngu·ªìn n·∫øu c√≥
                if show_rag_details and detailed_sources:
                    st.markdown("**üìö Chi ti·∫øt ngu·ªìn t√†i li·ªáu:**")
                    for j, source in enumerate(detailed_sources, 1):
                        with st.expander(f"Ngu·ªìn {j}: {source.get('title', 'N/A')}"):
                            st.markdown(f"**T√°c gi·∫£:** {source.get('author', 'N/A')}")
                            st.markdown(f"**Th·ªùi gian:** {source.get('time_posted', 'N/A')}")
                            st.markdown(f"**Tags:** {source.get('tags', 'N/A')}")
                            st.markdown(f"**Similarity Score:** {source.get('similarity_score', 0):.4f}")
                            if source.get('url') and source.get('url') != 'N/A':
                                st.markdown(f"**URL:** {source.get('url')}")
                
                # Hi·ªÉn th·ªã query results n·∫øu c√≥
                if show_rag_details and chat_item.get('query_results'):
                    st.markdown("**üìä K·∫øt qu·∫£ truy v·∫•n RAG:**")
                    for j, result in enumerate(chat_item['query_results'][:3], 1):
                        with st.expander(f"K·∫øt qu·∫£ {j}"):
                            st.text(result[:500] + "..." if len(result) > 500 else result)

    # Form nh·∫≠p c√¢u h·ªèi
    st.markdown("---")
    with st.form("chat_form", clear_on_submit=True):
        st.markdown("### üîç ƒê·∫∑t c√¢u h·ªèi m·ªõi")
        
        # Input v·ªõi c√°c t√πy ch·ªçn
        col1, col2 = st.columns([5, 1])
        
        with col1:
            query = st.text_input(
                "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
                placeholder="V√≠ d·ª•: T√¨nh h√¨nh kinh t·∫ø Vi·ªát Nam hi·ªán t·∫°i nh∆∞ th·∫ø n√†o?",
                help="H·ªá th·ªëng s·∫Ω t√¨m ki·∫øm trong RAG tr∆∞·ªõc, sau ƒë√≥ s·ª≠ d·ª•ng OpenAI GPT ƒë·ªÉ tr·∫£ l·ªùi"
            )
        
        with col2:
            submit_button = st.form_submit_button(
                "üöÄ G·ª≠i", 
                use_container_width=True,
                help="Nh·∫•n ƒë·ªÉ g·ª≠i c√¢u h·ªèi"
            )

    # X·ª≠ l√Ω khi c√≥ c√¢u h·ªèi
    if submit_button and query:
        if query.strip():
            # B·∫Øt ƒë·∫ßu x·ª≠ l√Ω
            start_time = time.time()
            
            # Container cho qu√° tr√¨nh x·ª≠ l√Ω
            processing_container = st.container()
            
            with processing_container:
                st.markdown("### üîÑ ƒêang x·ª≠ l√Ω c√¢u h·ªèi...")
                
                # Hi·ªÉn th·ªã c√¢u h·ªèi
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>üßë B·∫°n h·ªèi:</strong> {query}
                </div>
                """, unsafe_allow_html=True)
                
                # Progress bar v√† status
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # B∆∞·ªõc 1: Truy v·∫•n RAG
                    if show_processing_steps:
                        st.markdown('<div class="processing-step">üîç B∆∞·ªõc 1: Truy v·∫•n c∆° s·ªü d·ªØ li·ªáu RAG...</div>', unsafe_allow_html=True)
                    
                    status_text.text("üîç ƒêang t√¨m ki·∫øm trong vector database...")
                    progress_bar.progress(25)
                    
                    # Truy v·∫•n RAG tr·ª±c ti·∫øp
                    rag_results = get_query_results_debug(query, k=max_results)
                    
                    # Ki·ªÉm tra k·∫øt qu·∫£ RAG
                    has_rag_data = len(rag_results) > 0
                    
                    if has_rag_data:
                        st.markdown(f"""
                        <div class="rag-status rag-found">
                            ‚úÖ T√¨m th·∫•y {len(rag_results)} k·∫øt qu·∫£ t·ª´ RAG
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class="rag-status rag-not-found">
                            ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu RAG - S·∫Ω s·ª≠ d·ª•ng ki·∫øn th·ª©c chung
                        </div>
                        """, unsafe_allow_html=True)
                    
                    progress_bar.progress(50)
                    
                    # B∆∞·ªõc 2: X·ª≠ l√Ω v·ªõi OpenAI GPT
                    if show_processing_steps:
                        st.markdown('<div class="processing-step">üß† B∆∞·ªõc 2: X·ª≠ l√Ω v·ªõi OpenAI GPT...</div>', unsafe_allow_html=True)
                    
                    status_text.text("ü§ñ ƒêang x·ª≠ l√Ω v·ªõi OpenAI GPT...")
                    progress_bar.progress(75)
                    
                    # G·ªçi ask_chatbot ƒë·ªÉ x·ª≠ l√Ω
                    chatbot_result = ask_chatbot(query)
                    
                    # X·ª≠ l√Ω k·∫øt qu·∫£
                    if isinstance(chatbot_result, dict):
                        answer = chatbot_result.get('answer', 'Xin l·ªói, kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi.')
                        sources = chatbot_result.get('sources', [])
                        source_summary = chatbot_result.get('source_summary', '')
                        source_count = chatbot_result.get('source_count', 0)
                        has_rag_context = chatbot_result.get('has_rag_context', False)
                        detailed_sources = chatbot_result.get('detailed_sources', [])
                        query_results = chatbot_result.get('query_results', [])
                    else:
                        answer = str(chatbot_result)
                        sources = []
                        source_summary = ''
                        source_count = 0
                        has_rag_context = False
                        detailed_sources = []
                        query_results = []
                    
                    progress_bar.progress(90)
                    
                    # B∆∞·ªõc 3: Ho√†n th√†nh
                    if show_processing_steps:
                        st.markdown('<div class="processing-step">‚ú® B∆∞·ªõc 3: Ho√†n th√†nh x·ª≠ l√Ω...</div>', unsafe_allow_html=True)
                    
                    status_text.text("‚úÖ Ho√†n th√†nh x·ª≠ l√Ω!")
                    progress_bar.progress(100)
                    
                    # T√≠nh th·ªùi gian x·ª≠ l√Ω
                    processing_time = time.time() - start_time
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    st.markdown("### ‚ú® C√¢u tr·∫£ l·ªùi:")
                    
                    # Hi·ªÉn th·ªã tr·∫°ng th√°i RAG cu·ªëi c√πng
                    if has_rag_context:
                        st.markdown(f"""
                        <div class="rag-status rag-found">
                            ‚úÖ C√¢u tr·∫£ l·ªùi d·ª±a tr√™n {source_count} ngu·ªìn t·ª´ RAG
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class="rag-status rag-not-found">
                            ‚ö†Ô∏è C√¢u tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c chung (kh√¥ng c√≥ d·ªØ li·ªáu RAG)
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
                    st.markdown(f"""
                    <div class="chat-message bot-message">
                        <strong>ü§ñ Bot:</strong> {answer}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã th√¥ng tin b·ªï sung
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("‚è±Ô∏è Th·ªùi gian", f"{processing_time:.2f}s")
                    with col2:
                        st.metric("üîç RAG Status", "‚úÖ C√≥ d·ªØ li·ªáu" if has_rag_context else "‚ùå Kh√¥ng c√≥")
                    with col3:
                        st.metric("üìö Ngu·ªìn", source_count)
                    with col4:
                        st.metric("üß† Model", "OpenAI GPT")
                    
                    # Hi·ªÉn th·ªã th√¥ng tin ngu·ªìn
                    if show_source_details and source_summary:
                        st.markdown("### üìö Ngu·ªìn t√†i li·ªáu tham kh·∫£o:")
                        st.markdown(f"""
                        <div class="source-info">
                            {source_summary}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã chi ti·∫øt RAG n·∫øu ƒë∆∞·ª£c b·∫≠t
                    if show_rag_details and has_rag_context:
                        st.markdown("### üìä Chi ti·∫øt k·∫øt qu·∫£ RAG:")
                        
                        # Hi·ªÉn th·ªã c√°c ngu·ªìn chi ti·∫øt
                        if detailed_sources:
                            for i, source in enumerate(detailed_sources, 1):
                                with st.expander(f"Ngu·ªìn {i}: {source.get('title', 'N/A')} (Score: {source.get('similarity_score', 0):.4f})"):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.markdown(f"**T√°c gi·∫£:** {source.get('author', 'N/A')}")
                                        st.markdown(f"**Th·ªùi gian:** {source.get('time_posted', 'N/A')}")
                                    with col2:
                                        st.markdown(f"**Tags:** {source.get('tags', 'N/A')}")
                                        st.markdown(f"**Similarity:** {source.get('similarity_score', 0):.4f}")
                                    
                                    if source.get('url') and source.get('url') != 'N/A':
                                        st.markdown(f"**URL:** {source.get('url')}")
                        
                        # Hi·ªÉn th·ªã n·ªôi dung truy v·∫•n
                        if query_results:
                            st.markdown("**üìù N·ªôi dung ƒë∆∞·ª£c t√¨m th·∫•y:**")
                            for i, result in enumerate(query_results[:3], 1):
                                with st.expander(f"K·∫øt qu·∫£ {i}"):
                                    st.text_area(f"Content {i}", result, height=150, disabled=True)
                    
                    # L∆∞u v√†o l·ªãch s·ª≠
                    chat_item = {
                        'question': query,
                        'answer': answer,
                        'sources': sources,
                        'source_summary': source_summary,
                        'source_count': source_count,
                        'has_rag_context': has_rag_context,
                        'detailed_sources': detailed_sources,
                        'query_results': query_results,
                        'processing_time': processing_time,
                        'timestamp': datetime.now().strftime('%H:%M:%S %d/%m/%Y')
                    }
                    st.session_state.chat_history.append(chat_item)
                    
                    # X√≥a progress bar
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng
                    st.markdown(f"""
                    <div class="success-message">
                        ‚úÖ ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng c√¢u h·ªèi trong {processing_time:.2f} gi√¢y!
                        {'S·ª≠ d·ª•ng RAG context' if has_rag_context else 'S·ª≠ d·ª•ng ki·∫øn th·ª©c chung'}
                    </div>
                    """, unsafe_allow_html=True)
                    
                except Exception as e:
                    st.markdown(f"""
                    <div class="error-message">
                        ‚ùå L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}
                    </div>
                    """, unsafe_allow_html=True)
                    progress_bar.empty()
                    status_text.empty()
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi!")

    # Footer v√† c√°c n√∫t ƒëi·ªÅu khi·ªÉn
    st.markdown("---")
    
    # N√∫t ƒëi·ªÅu khi·ªÉn
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.session_state.chat_history:
            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
                st.session_state.chat_history = []
                st.rerun()
    
    with col2:
        if st.button("üîÑ Kh·ªüi t·∫°o l·∫°i h·ªá th·ªëng", use_container_width=True):
            st.session_state.qa_chain = None
            st.session_state.system_ready = False
            st.rerun()
    
    with col3:
        if st.button("üíæ Xu·∫•t l·ªãch s·ª≠", use_container_width=True):
            if st.session_state.chat_history:
                # T·∫°o d·ªØ li·ªáu xu·∫•t
                export_data = []
                for item in st.session_state.chat_history:
                    export_data.append({
                        'C√¢u h·ªèi': item['question'],
                        'C√¢u tr·∫£ l·ªùi': item['answer'],
                        'C√≥ RAG': 'C√≥' if item.get('has_rag_context') else 'Kh√¥ng',
                        'S·ªë ngu·ªìn': item.get('source_count', 0),
                        'Th·ªùi gian x·ª≠ l√Ω': f"{item.get('processing_time', 0):.2f}s",
                        'Th·ªùi gian': item['timestamp'],
                        'Ngu·ªìn': item.get('source_summary', 'Kh√¥ng c√≥')
                    })
                
                # T·∫°o n·ªôi dung file
                import json
                export_content = json.dumps(export_data, ensure_ascii=False, indent=2)
                
                st.download_button(
                    label="üì• T·∫£i file JSON",
                    data=export_content,
                    file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )

    # Footer
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 1rem;'>
        <p>ü§ñ Powered by RAG + OpenAI GPT | üîç Vector Search | üìä Smart Context Processing</p>
        <p style='font-size: 0.8rem;'>H·ªá th·ªëng truy v·∫•n vector database v√† x·ª≠ l√Ω AI th√¥ng minh</p>
    </div>
    """, unsafe_allow_html=True)


# Ch·∫°y ·ª©ng d·ª•ng
# if __name__ == "__main__":
#     # C·∫•u h√¨nh trang
#     st.set_page_config(
#         page_title="RAG + OpenAI Chatbot", 
#         page_icon="ü§ñ",
#         layout="wide",
#         initial_sidebar_state="expanded",
#         menu_items={
#             'Get Help': 'https://github.com/your-repo',
#             'Report a bug': 'https://github.com/your-repo/issues',
#             'About': 'RAG + OpenAI Chatbot - H·ªá th·ªëng h·ªèi ƒë√°p th√¥ng minh v·ªõi vector search'
#         }
#     )
    
#     show_chat()